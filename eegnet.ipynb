{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEGNET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHYUzox6QlAd"
      },
      "source": [
        "## Installo librerie ausiliarie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYFza8Rrb0aQ"
      },
      "source": [
        "!pip install torchaudio pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8GKHgj84clT"
      },
      "source": [
        "## Caricamento Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K43B4JY3cIeD",
        "outputId": "647e8535-e521-470e-e62e-5313fd081291"
      },
      "source": [
        "import torch, torchaudio\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics import functional\n",
        "\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hujbm0oh4XNK"
      },
      "source": [
        "## Caricamento Dati\n",
        "\n",
        "\n",
        "I dati sono salvati in file pickle per comodità sotto forma di HASH table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEIH4mGUkDcV"
      },
      "source": [
        "feat = pickle.load(open(\"drive/My Drive/EEGNET/features.pkl\", \"rb\"))\n",
        "eeg = pickle.load(open(\"drive/My Drive/EEGNET/eeg.pkl\", \"rb\"))\n",
        "\n",
        "X = torch.from_numpy(feat['X'])\n",
        "y = torch.from_numpy(feat['y'])\n",
        "eeg = torch.from_numpy(eeg['EEG'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KozSZW_q5mTf"
      },
      "source": [
        "## Classe per la gestione dei dataset in PyTorch.\n",
        "\n",
        "Nell'inizializzazione vengono caricati i dati grezzi e prima di fornirli in input alla rete neurale, vengono applicate delle trasformazioni standard (Resamplin, Costruzione spettrogramma, Amplificazione)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMmGmBmeZe3"
      },
      "source": [
        "class EEGDataset(torch.utils.data.Dataset):\n",
        "    # Simple class to load the desired folders inside ESC-50\n",
        "    \n",
        "    def __init__(self, path: Path = Path(\"drive/My Drive/EEGNET\"), \n",
        "                 sample_rate: int = 8000):\n",
        "        # Load CSV & initialize all torchaudio.transforms:\n",
        "        # Resample --> MelSpectrogram --> AmplitudeToDB\n",
        "\n",
        "        feat = pickle.load(open(\"drive/My Drive/EEGNET/features.pkl\", \"rb\"))\n",
        "        eeg = pickle.load(open(\"drive/My Drive/EEGNET/eeg.pkl\", \"rb\"))\n",
        "\n",
        "        self.X = torch.from_numpy(feat['X']).float()\n",
        "        self.y = torch.from_numpy(feat['y']).float()\n",
        "        self.eeg = torch.from_numpy(eeg['EEG']).float()\n",
        "\n",
        "        self.resample = torchaudio.transforms.Resample(\n",
        "            orig_freq=250, new_freq=sample_rate\n",
        "        ) #useful?\n",
        "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sample_rate)\n",
        "        self.db = torchaudio.transforms.AmplitudeToDB(top_db=80)\n",
        "        \n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # Returns (xb, yb) pair, after applying all transformations on the audio file.\n",
        "        \n",
        "        wav = self.eeg[index]\n",
        "        label = self.y[index]\n",
        "        \n",
        "        tmp = []\n",
        "        for w in wav:\n",
        "          tmp.append(self.db(\n",
        "            self.melspec(\n",
        "                self.resample(w.reshape(1, -1))\n",
        "            )\n",
        "        ))\n",
        "\n",
        "        xb = torch.vstack(tmp)\n",
        "        \n",
        "        return xb, label\n",
        "        \n",
        "    def __len__(self):\n",
        "        # Returns length\n",
        "        return len(self.eeg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo1WXk1Q6FDf"
      },
      "source": [
        "Verifico la dimensione dei tensori di input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ow6eLmmGQu"
      },
      "source": [
        "train_data = EEGDataset()\n",
        "for xb, yb in train_data:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4XP3QS8mKu4",
        "outputId": "7343853c-63e4-45c9-f98e-2d677b4a8043"
      },
      "source": [
        "xb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 1199])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybpod8sE6I4Y"
      },
      "source": [
        "yb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIQkI81z6KZD"
      },
      "source": [
        "## Streaming dei dati\n",
        "\n",
        "Per usufruire degli algoritmi stocastici, i dati vengono caricati a gruppi tramite uno strumento fornito da PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKVK2kSxn6uE"
      },
      "source": [
        "# We use folds 1,2,3 for training, 4 for validation, 5 for testing.\n",
        "train_data = EEGDataset()\n",
        "val_data = EEGDataset()\n",
        "test_data = EEGDataset()\n",
        "\n",
        "train_loader = \\\n",
        "    torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO0FK9Eh6d6t"
      },
      "source": [
        "## Definizione del Modello\n",
        "\n",
        "Avendo calcolato lo spettrogramma del segnale EEG, possiamo utilizzare tutte le operazioni di filtraggio e sub-sampling riservati a dati definiti su un dominio bidimensionale. \n",
        "\n",
        "Di fatto, trattiamo il segnale audio come se fosse un'immagine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub3Idk-DoFo1"
      },
      "source": [
        "class EEGNet(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, n_classes = 1, base_filters = 32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(32, base_filters, 11, padding=5)\n",
        "        self.bn1 = nn.BatchNorm2d(base_filters)\n",
        "        self.conv2 = nn.Conv2d(base_filters, base_filters, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(base_filters)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(base_filters, base_filters * 2, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(base_filters * 2)\n",
        "        self.conv4 = nn.Conv2d(base_filters * 2, base_filters * 4, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(base_filters * 4)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(base_filters * 4, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = self.fc1(x[:, :, 0, 0])\n",
        "        return torch.squeeze(x)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Very simple training loop\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        lam = 1e-3\n",
        "        bet = 1e-3\n",
        "        range_loss = bet * (y_hat - 100) -  lam * y_hat # Lagrangian per avere y in [0, 100]\n",
        "        loss = F.l1_loss(y_hat, y) + range_loss.sum()\n",
        "        self.log('train_loss', loss, on_step=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.l1_loss(y_hat, y) \n",
        "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "      return self.validation_step(batch, batch_idx)\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-3)\n",
        "        return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ4yfRwMoROp",
        "outputId": "66881ff9-d5b8-4b2a-9545-ddffaeb758d2"
      },
      "source": [
        "pl.seed_everything(0)\n",
        "# Test that the network works on a single mini-batch\n",
        "eegnet = EEGNet()\n",
        "#xb, yb = next(iter(train_loader))\n",
        "#eegnet(xb).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2wwAYx4tuOD",
        "outputId": "f73555b2-7e77-423a-ce4d-8219c05b0283"
      },
      "source": [
        "yb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oNZGFPjVBVx",
        "outputId": "c8de9cd1-9ba5-45c4-8254-9a2c307d57bf"
      },
      "source": [
        "eegnet(xb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4977, -0.4721, -0.5407, -0.4707, -0.5965, -0.3359, -0.9113, -0.3669,\n",
              "        -0.5221, -0.6379], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnULM6ECQbEU"
      },
      "source": [
        "Addestro la rete neurale per 35 epoche (test di funzionamento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLrZK6j2oTP7"
      },
      "source": [
        "trainer = pl.Trainer(gpus=1, max_epochs=35)\n",
        "trainer.fit(eegnet, train_loader, val_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt9DfCD3Wk8z",
        "outputId": "9be7bb30-f922-4833-c802-0909dcb042cd"
      },
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "eegnet(xb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([55.0547, 51.6868], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9XM02zSf4OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3de91f-701c-43cf-c875-8398ae3a444f"
      },
      "source": [
        "yb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([63., 61.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18b_ACbUolmA"
      },
      "source": [
        "# TODO: implement the test loop.\n",
        "trainer.test(audionet, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FVH2xubrrE4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}